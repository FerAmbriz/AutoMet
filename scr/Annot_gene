#!/usr/bin/env python3
#import os
#os.environ['OPENBLAS_NUM_THREADS'] = '1'

import sys
import requests
import io
import csv
import pandas as pd
from tqdm import tqdm
from tqdm.contrib.concurrent import process_map
from multiprocessing import Pool

bed_file = sys.argv[1]
ref = sys.argv[2]
output = sys.argv[3]
threads = int(sys.argv[4])

url = 'https://genome.ucsc.edu/cgi-bin/hgTables?hgsid=1442153227_FWCo6wJtrFjEzVt07A5mEs5LeL3m'
session = requests.Session()
params = {
        'hgsid': '1442153227_FWCo6wJtrFjEzVt07A5mEs5LeL3m',
        'db': ref,
        'hgta_group': 'genes',
        'hgta_track': 'refSeqComposite',
        'hgta_table': 'ncbiRefSeq',
        'hgta_regionType': 'genome',
        'hgta_outputType': 'primaryTable',
        'boolshad.sendToGalaxy': '0',
        'boolshad.sendToGreat': '0',
        'boolshad.sendToGenomeSpace': '0',
        'hgta_outFileName': '',
        'hgta_compressType': 'none',
        'hgta_doTopSubmit': 'get output'
    }

response = session.post(url, data=params)
df = pd.read_csv(io.StringIO(response.text), sep='\t')

df = df.drop_duplicates(subset=["name2"])
print('Done extract data from UCSC')

bed = pd.read_csv(bed_file)
if 'Chr' not in list(bed.columns):
    bed.rename(columns = {'Unnamed: 0':'Chr'}, inplace = True)

#==================================Function======================================
def paralell_search (site, chrom):
    df_i = df[df['chrom']==chrom]
    indicador  = 'off-target'
    for i,j,gene,st,acc in zip(df_i.txStart, df_i.txEnd, df_i['name2'], df_i.strand, df_i.name):
        if site in list(range(i,j)):
            return [chrom, site, site, gene, st, acc]
            indicador = 'on-target'
    if indicador == 'off-target':
        return [chrom, site,  site, 'NaN', 'NaN', 'NaN']

#================================================================================

if 'Depth' not in list(bed.columns):
    print('Processing bed')
    if 'Gene' in list(bed.columns):
        df_annot = bed
        df_annot.to_csv(output + '/anotate_bed.csv', index=False)
    else:
        array = process_map(paralell_search, bed.Start, bed.Chr, max_workers=threads)
        df_annot = pd.DataFrame(array)
        df_annot.columns = ['Chr', 'Start', 'End', 'Gene', 'Strand', 'AccessName']
        df_annot.to_csv(output + '/anotate_bed.csv', index=False)
else:
    print('Processing merge')
    # Procesado del merge
    bed = bed.drop(['End',  'Cyt_Met', 'Cyt_NoMet', 'Depth', 'Status'], axis=1)
    bed = bed.pivot(index=['Chr', 'Start'], columns = ['Sample'])
    bed = bed.reset_index()
    bed.columns = bed.columns.droplevel(1)
    print(bed[['Chr', 'Start']])
    array = process_map(paralell_search, bed.Start, bed.Chr, max_workers=threads)
    df_annot = pd.DataFrame(array)
    df_annot.columns = ['Chr', 'Start', 'End', 'Gene', 'Strand', 'AccessName']
    print(df_annot)
    df_annot.to_csv(output + '/anotate_bed.csv', index=False)
